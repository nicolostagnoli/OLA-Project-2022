{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OLA_pricing2.0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "class UserClass:\n",
        "  def __init__(self,number_of_user, alfas, num_products_bought, p_matrix ) :\n",
        "    self.conversion_rate_matrix = np.random.uniform(0.0,1.0,(5,4))      #randomly generates the conversion rates for every price\n",
        "    self.number_of_user = number_of_user\n",
        "    self.alfas = alfas\n",
        "    self.num_products_bought = num_products_bought\n",
        "    self.p_matrix = p_matrix\n",
        "  \n",
        "class Product:\n",
        "    def __init__(self,id, price_vector) :\n",
        "      self.id = id\n",
        "      self.price_vector = price_vector\n"
      ],
      "metadata": {
        "id": "v4XSxxUEB83n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_episode(init_prob_matrix, n_steps_max, initial_product, lambd, buy_probability_matrix, price_index):\n",
        "    prob_matrix = init_prob_matrix.copy()\n",
        "    n_nodes = prob_matrix.shape[0]\n",
        "    initial_active_nodes = np.zeros(5, dtype=int)\n",
        "    initial_active_nodes[initial_product] = 1\n",
        "    history = np.array([initial_active_nodes])\n",
        "    active_nodes = initial_active_nodes\n",
        "    newly_active_nodes = active_nodes\n",
        "    t=0\n",
        "\n",
        "    while(t < n_steps_max and np.sum(newly_active_nodes) > 0):\n",
        "        #print(\"giro \", t)\n",
        "        #print(prob_matrix)\n",
        "\n",
        "        #buy_or_not_nodes = buy_or_not( active_nodes, userClass, product_indx, price) \n",
        "        buy_or_not_nodes = np.zeros(5)\n",
        "        for i, node in enumerate(active_nodes):\n",
        "            if node == 1:\n",
        "                random_sample = np.random.uniform(0.0, 1.0)\n",
        "                buy_or_not_nodes[i] = random_sample < buy_probability_matrix[i][price_index[i]]\n",
        "\n",
        "        p = (prob_matrix.T * buy_or_not_nodes).T\n",
        "\n",
        "        #print(\"p matrix : \\n\", p)\n",
        "        #p is used to select from the prob matrix only the rows with active nodes  (.T compute the transpose)... returns the set of probabilities corresponding to the edges leaving from an active_node\n",
        "        lambda_vector = np.zeros(n_nodes)\n",
        "        lambda_matrix = np.zeros(shape = (n_nodes, n_nodes))\n",
        "        for i in range(0, n_nodes):\n",
        "            idx1 = -1\n",
        "            idx2 = -1\n",
        "            lambda_vector = np.zeros(5)\n",
        "            while(idx1 == idx2 or idx1 == i or idx2 == i):\n",
        "                [idx1, idx2] = np.random.choice(5, 2)\n",
        "            lambda_vector[idx1] = 1\n",
        "            lambda_vector[idx2] = lambd\n",
        "            lambda_matrix[i] = lambda_vector\n",
        "        #lambda matrix has primary products on the rows, secondary on the columns, 1 if the secondary is in the first slot, lambda otherwise \n",
        "        #print(\"lambda matrix : \\n\", lambda_matrix)\n",
        "        p = (p * lambda_matrix)\n",
        "        #print(\"p after lambda vec : \\n\", p)\n",
        "        activated_edges = p > np.random.rand(p.shape[0], p.shape[1])\n",
        "        #print(\"activated edges : \\n\", activated_edges)\n",
        "        prob_matrix = prob_matrix * ((p!=0) == activated_edges)\n",
        "        newly_active_nodes = (np.sum(activated_edges, axis=0) > 0) * (1 - active_nodes)\n",
        "        active_nodes = np.array(active_nodes + newly_active_nodes)\n",
        "        #print(\"active nodes at t+1: \\n\", active_nodes)\n",
        "        history = np.concatenate((history, [newly_active_nodes]), axis = 0)\n",
        "        #print(\"history : \\n\", history)\n",
        "        t += 1\n",
        "\n",
        "        #all edges leaving from the node that didn't buy go to 0 \n",
        "        \n",
        "    return history"
      ],
      "metadata": {
        "id": "sbM8CaTBFlXC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ddoiKA9IlO2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb11dded-6b58-4f7b-e77e-7cf12abe4d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting prices:  [10, 10, 10, 10, 10]\n",
            "prices index:  [0 0 0 0 0]\n",
            "Lowest prices reward:  4210.0\n",
            "Iteration\n",
            "Experiment reward:  5050.0\n",
            "Experiment reward:  5510.0\n",
            "Experiment reward:  4740.0\n",
            "Experiment reward:  5210.0\n",
            "Experiment reward:  5380.0\n",
            "Product to raise:  1\n",
            "current prices:  [10, 20, 10, 10, 10]\n",
            "current prices index:  [0 1 0 0 0]\n",
            "Iteration\n",
            "Experiment reward:  6210.0\n",
            "Experiment reward:  6350.0\n",
            "Experiment reward:  6230.0\n",
            "Experiment reward:  6140.0\n",
            "Experiment reward:  6140.0\n",
            "Product to raise:  1\n",
            "current prices:  [10, 30, 10, 10, 10]\n",
            "current prices index:  [0 2 0 0 0]\n",
            "Iteration\n",
            "Experiment reward:  7170.0\n",
            "Experiment reward:  7300.0\n",
            "Experiment reward:  7150.0\n",
            "Experiment reward:  6650.0\n",
            "Experiment reward:  7570.0\n",
            "Product to raise:  4\n",
            "current prices:  [10, 30, 10, 10, 20]\n",
            "current prices index:  [0 2 0 0 1]\n",
            "Iteration\n",
            "Experiment reward:  7830.0\n",
            "Experiment reward:  8240.0\n",
            "Experiment reward:  8040.0\n",
            "Experiment reward:  7740.0\n",
            "Experiment reward:  8150.0\n",
            "Product to raise:  1\n",
            "current prices:  [10, 40, 10, 10, 20]\n",
            "current prices index:  [0 3 0 0 1]\n",
            "Iteration\n",
            "Experiment reward:  9060.0\n",
            "Experiment reward:  8390.0\n",
            "Experiment reward:  8970.0\n",
            "Experiment reward:  9150.0\n",
            "Experiment reward:  9320.0\n",
            "Product to raise:  4\n",
            "current prices:  [10, 40, 10, 10, 30]\n",
            "current prices index:  [0 3 0 0 2]\n",
            "Iteration\n",
            "Experiment reward:  9960.0\n",
            "Experiment reward:  9050.0\n",
            "Experiment reward:  9650.0\n",
            "Experiment reward:  9810.0\n",
            "Experiment reward:  9720.0\n",
            "Product to raise:  0\n",
            "current prices:  [20, 40, 10, 10, 30]\n",
            "current prices index:  [1 3 0 0 2]\n",
            "Iteration\n",
            "Experiment reward:  10870.0\n",
            "Experiment reward:  9400.0\n",
            "Experiment reward:  10090.0\n",
            "Experiment reward:  10800.0\n",
            "Experiment reward:  10180.0\n",
            "Product to raise:  0\n",
            "current prices:  [30, 40, 10, 10, 30]\n",
            "current prices index:  [2 3 0 0 2]\n",
            "Iteration\n",
            "Experiment reward:  11460.0\n",
            "Experiment reward:  10220.0\n",
            "Experiment reward:  11910.0\n",
            "Experiment reward:  11290.0\n",
            "Experiment reward:  11400.0\n",
            "Product to raise:  2\n",
            "current prices:  [30, 40, 20, 10, 30]\n",
            "current prices index:  [2 3 1 0 2]\n",
            "Iteration\n",
            "Experiment reward:  12150.0\n",
            "Experiment reward:  11080.0\n",
            "Experiment reward:  12380.0\n",
            "Experiment reward:  12480.0\n",
            "Experiment reward:  11350.0\n",
            "Product to raise:  3\n",
            "current prices:  [30, 40, 20, 20, 30]\n",
            "current prices index:  [2 3 1 1 2]\n",
            "Iteration\n",
            "Experiment reward:  13200.0\n",
            "Experiment reward:  11790.0\n",
            "Experiment reward:  13250.0\n",
            "Experiment reward:  12580.0\n",
            "Experiment reward:  12060.0\n",
            "Product to raise:  2\n",
            "current prices:  [30, 40, 30, 20, 30]\n",
            "current prices index:  [2 3 2 1 2]\n",
            "Iteration\n",
            "Experiment reward:  13960.0\n",
            "Experiment reward:  13270.0\n",
            "Experiment reward:  14130.0\n",
            "Experiment reward:  13510.0\n",
            "Experiment reward:  13110.0\n",
            "Product to raise:  2\n",
            "current prices:  [30, 40, 40, 20, 30]\n",
            "current prices index:  [2 3 3 1 2]\n",
            "Iteration\n",
            "Experiment reward:  13800.0\n",
            "Experiment reward:  13510.0\n",
            "Experiment reward:  14140.0\n",
            "Experiment reward:  14360.0\n",
            "Experiment reward:  14080.0\n",
            "Product to raise:  3\n",
            "current prices:  [30, 40, 40, 30, 30]\n",
            "current prices index:  [2 3 3 2 2]\n",
            "Iteration\n",
            "Experiment reward:  15450.0\n",
            "Experiment reward:  14260.0\n",
            "Experiment reward:  13930.0\n",
            "Experiment reward:  15490.0\n",
            "Experiment reward:  15020.0\n",
            "Product to raise:  3\n",
            "current prices:  [30, 40, 40, 40, 30]\n",
            "current prices index:  [2 3 3 3 2]\n",
            "Iteration\n",
            "Experiment reward:  16020.0\n",
            "Experiment reward:  16150.0\n",
            "Experiment reward:  16190.0\n",
            "Experiment reward:  16030.0\n",
            "Experiment reward:  16070.0\n",
            "Product to raise:  4\n",
            "current prices:  [30, 40, 40, 40, 40]\n",
            "current prices index:  [2 3 3 3 3]\n",
            "Iteration\n",
            "Experiment reward:  17400.0\n",
            "Experiment reward:  16340.0\n",
            "Experiment reward:  16940.0\n",
            "Experiment reward:  17570.0\n",
            "Experiment reward:  17360.0\n",
            "Product to raise:  0\n",
            "current prices:  [40, 40, 40, 40, 40]\n",
            "current prices index:  [3 3 3 3 3]\n",
            "Iteration\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#\n",
        "#\n",
        "# Fist Step: Greedy Algorithm \n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "p_matrix = np.array([[0,0.5,0,0.5,0],\n",
        "                     [0.5,0,0.5,0,0],\n",
        "                     [0,0.5,0,0,0.5],\n",
        "                     [0.5,0,0,0,0.5],\n",
        "                     [0,0.5,0,0.5,0]], dtype = float)\n",
        "num_products_bought = [1, 1, 1, 1, 1]\n",
        "userClass1 = UserClass(100, np.random.dirichlet([1, 1, 1, 1, 1]), num_products_bought, p_matrix )\n",
        "userClass2 = UserClass(200, np.random.dirichlet([1, 1, 1, 1, 1]), num_products_bought, p_matrix )\n",
        "userClass3 = UserClass(50, np.random.dirichlet([1, 1, 1, 1, 1]), num_products_bought, p_matrix )\n",
        "userClasses = [userClass1, userClass2, userClass3]\n",
        "\n",
        "price_vector = [10, 20, 30, 40]\n",
        "p1 = Product(\"p1\", price_vector )\n",
        "p2 = Product(\"p2\", price_vector )\n",
        "p3 = Product(\"p3\", price_vector )\n",
        "p4 = Product(\"p4\", price_vector )\n",
        "p5 = Product(\"p5\", price_vector )\n",
        "\n",
        "total_daily_users = userClass1.number_of_user + userClass2.number_of_user + userClass3.number_of_user\n",
        "n_episodes = 100\n",
        "\n",
        "optimal_prices = [p1.price_vector[0], p2.price_vector[0], p3.price_vector[0], p4.price_vector[0], p5.price_vector[0]]\n",
        "optimal_prices_index = np.zeros(5, dtype=int)\n",
        "best_total_revenue = 0\n",
        "\n",
        "print(\"starting prices: \", optimal_prices)\n",
        "print(\"prices index: \", optimal_prices_index)\n",
        " \n",
        "#first iteration to evaluate the \"base\" revenue with lowest prices for every product\n",
        "for uc in userClasses:\n",
        "  for j in range(0, uc.number_of_user):\n",
        "    initial_product = np.random.choice(5, 1, [a for a in uc.alfas])[0]\n",
        "\n",
        "    history = simulate_episode(uc.p_matrix, 10, initial_product, 0.5, uc.conversion_rate_matrix, optimal_prices_index)\n",
        "    \n",
        "    tot_products_bought = np.zeros(5)\n",
        "\n",
        "    for row in history:\n",
        "      tot_products_bought +=  row\n",
        "\n",
        "    tot_products_bought *= uc.num_products_bought\n",
        "    revenue_per_user = np.sum(tot_products_bought*optimal_prices)\n",
        "    best_total_revenue += revenue_per_user\n",
        "\n",
        "print(\"Lowest prices reward: \", best_total_revenue)\n",
        "\n",
        "#try to raise one price at time and calculate reward\n",
        "stop = False\n",
        "while(not stop):\n",
        "    print(\"Iteration\")\n",
        "    temp_revenue = np.zeros(5)\n",
        "    if np.all(optimal_prices_index == 3):\n",
        "        break\n",
        "    for i in range(0, 5):\n",
        "        total_revenue = 0\n",
        "        temp_price_index = np.copy(optimal_prices_index)\n",
        "        temp_price_index[i] += 1\n",
        "        for indx in temp_price_index:\n",
        "            if indx > 3: temp_price_index[i] = 3\n",
        "        temp_optimal_prices = [p1.price_vector[temp_price_index[0]], p2.price_vector[temp_price_index[1]], p3.price_vector[temp_price_index[2]],\n",
        "                               p4.price_vector[temp_price_index[3]], p5.price_vector[temp_price_index[4]]]\n",
        "\n",
        "        for uc in userClasses:\n",
        "            for j in range(0, uc.number_of_user):\n",
        "                initial_product = np.random.choice(5, 1, [a for a in uc.alfas])[0]\n",
        "                history = simulate_episode(uc.p_matrix, 10, initial_product, 0.5, uc.conversion_rate_matrix, temp_price_index)\n",
        "                tot_products_bought = np.zeros(5)\n",
        "                for row in history:\n",
        "                  tot_products_bought +=  row\n",
        "                tot_products_bought *= uc.num_products_bought\n",
        "                revenue_per_user = np.sum(tot_products_bought*temp_optimal_prices)\n",
        "                temp_revenue[i] += revenue_per_user\n",
        "\n",
        "        print(\"Experiment reward: \", temp_revenue[i])\n",
        "    \n",
        "    product_to_raise = np.argmax(temp_revenue)\n",
        "    while(optimal_prices_index[product_to_raise] >= 3):\n",
        "        temp_revenue[product_to_raise] = -1.0\n",
        "        product_to_raise = np.argmax(temp_revenue)\n",
        "    #after 5 experiments, check if the best experiment is better than the current configuration, then update prices\n",
        "    #if no experiment is better, stop\n",
        "    if(np.max(temp_revenue) > best_total_revenue):\n",
        "        best_total_revenue = np.max(temp_revenue)\n",
        "        optimal_prices_index[product_to_raise] += 1\n",
        "        optimal_prices = [p1.price_vector[optimal_prices_index[0]], p2.price_vector[optimal_prices_index[1]], p3.price_vector[optimal_prices_index[2]],\n",
        "                          p4.price_vector[optimal_prices_index[3]], p5.price_vector[optimal_prices_index[4]]]\n",
        "        print(\"Product to raise: \", product_to_raise)\n",
        "    else:\n",
        "        print(\"No increment in reward, stop\")\n",
        "        stop = True\n",
        "    \n",
        "    print(\"current prices: \", optimal_prices)\n",
        "    print(\"current prices index: \", optimal_prices_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3Eidm1EJloSr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up an arm for all the configurations of prices"
      ],
      "metadata": {
        "id": "Yc_ka-B5lofI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Learner:\n",
        "\n",
        "  def __init__(self, n_arms) :\n",
        "    self.n_arms = n_arms\n",
        "    self.t = 0\n",
        "    self.rewards_per_arm = x = [[] for i in range(n_arms)]\n",
        "    self.collected_rewards = np.array([])\n",
        "\n",
        "  def update_observations(self,pulled_arm, reward) :\n",
        "    self.rewards_per_arm[pulled_arm].append(reward)\n",
        "    self.collected_rewards = np.append(self.collected_rewards, reward)"
      ],
      "metadata": {
        "id": "d6cjJ6WdloiP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TS_Learner(Learner) :\n",
        "  def __init__(self, n_arms):\n",
        "    super().__init__(n_arms)\n",
        "    self.beta_parameters = np.ones((624, 2))\n",
        "\n",
        "  def pull_arm(self) :\n",
        "    idx = np.argmax(np.random.beta(self.beta_parameters[:,0 ], self.beta_parameters[:,1]))   #the expected rewards (our guess) are beta distributions( in the TS learner) (process: we draw an actual reward(aka sample) and based on what we have drawn we position and shape the binomila distribution of the expected reward)\n",
        "    return idx\n",
        "\n",
        "  def update(self, pulled_arm, reward):\n",
        "    self.t+1\n",
        "    self.update_observations(pulled_arm, reward)\n",
        "    self.beta_parameters[pulled_arm, 0] = self.beta_parameters[pulled_arm, 0] + reward\n",
        "    self.beta_parameters[pulled_arm,1] = self.beta_parameters[pulled_arm, 1] + 1.0 - reward"
      ],
      "metadata": {
        "id": "Rr5xju8Dlok1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "MUtWmvwiuepB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Arm:\n",
        "  def __init__(self, price_vector):\n",
        "      self.price_vector = price_vector\n",
        "\n"
      ],
      "metadata": {
        "id": "LaE25NQwvva6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_episode2(init_prob_matrix, n_steps_max, initial_product, lambd, buy_probability_matrix, price_index):\n",
        "    prob_matrix = init_prob_matrix.copy()\n",
        "    n_nodes = prob_matrix.shape[0]\n",
        "    initial_active_nodes = np.zeros(5, dtype=int)\n",
        "    initial_active_nodes[initial_product] = 1\n",
        "    history = np.array([initial_active_nodes])\n",
        "    active_nodes = initial_active_nodes\n",
        "    newly_active_nodes = active_nodes\n",
        "    t=0\n",
        "\n",
        "    while(t < n_steps_max and np.sum(newly_active_nodes) > 0):\n",
        "        #print(\"giro \", t)\n",
        "        #print(prob_matrix)\n",
        "\n",
        "        #buy_or_not_nodes = buy_or_not( active_nodes, userClass, product_indx, price) \n",
        "        buy_or_not_nodes = np.zeros(5)\n",
        "        for i, node in enumerate(active_nodes):\n",
        "            if node == 1:\n",
        "                random_sample = np.random.uniform(0.0, 1.0)\n",
        "                buy_or_not_nodes[i] = random_sample < buy_probability_matrix[i][price_index[i]]\n",
        "\n",
        "        p = (prob_matrix.T * buy_or_not_nodes).T\n",
        "\n",
        "        #print(\"p matrix : \\n\", p)\n",
        "        #p is used to select from the prob matrix only the rows with active nodes  (.T compute the transpose)... returns the set of probabilities corresponding to the edges leaving from an active_node\n",
        "        lambda_vector = np.zeros(n_nodes)\n",
        "        lambda_matrix = np.zeros(shape = (n_nodes, n_nodes))\n",
        "        for i in range(0, n_nodes):\n",
        "            idx1 = -1\n",
        "            idx2 = -1\n",
        "            lambda_vector = np.zeros(5)\n",
        "            while(idx1 == idx2 or idx1 == i or idx2 == i):\n",
        "                [idx1, idx2] = np.random.choice(5, 2)\n",
        "            lambda_vector[idx1] = 1\n",
        "            lambda_vector[idx2] = lambd\n",
        "            lambda_matrix[i] = lambda_vector\n",
        "        #lambda matrix has primary products on the rows, secondary on the columns, 1 if the secondary is in the first slot, lambda otherwise \n",
        "        #print(\"lambda matrix : \\n\", lambda_matrix)\n",
        "        p = (p * lambda_matrix)\n",
        "        #print(\"p after lambda vec : \\n\", p)\n",
        "        activated_edges = p > np.random.rand(p.shape[0], p.shape[1])\n",
        "        #print(\"activated edges : \\n\", activated_edges)\n",
        "        prob_matrix = prob_matrix * ((p!=0) == activated_edges)\n",
        "        newly_active_nodes = (np.sum(activated_edges, axis=0) > 0) * (1 - active_nodes)\n",
        "        active_nodes = np.array(active_nodes + newly_active_nodes)\n",
        "        #print(\"active nodes at t+1: \\n\", active_nodes)\n",
        "        history = np.concatenate((history, [newly_active_nodes]), axis = 0)\n",
        "        #print(\"history : \\n\", history)\n",
        "        t += 1\n",
        "\n",
        "        #all edges leaving from the node that didn't buy go to 0 \n",
        "\n",
        "    tot_products_bought = np.zeros(5)\n",
        "    for row in history:\n",
        "          tot_products_bought +=  row\n",
        "    tot_products_bought *= uc.num_products_bought\n",
        "    revenue_per_user = np.sum(tot_products_bought*temp_optimal_prices)\n",
        "    temp_revenue[i] += revenue_per_user   \n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "WShNWlrhH2rV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "range = [10, 20, 30, 40]\n",
        "arms_list = []\n",
        "\n",
        "tmp = [(x, y ,z, j ,k) for x in range for y in range for z in range for j in range for k in range]\n",
        "\n",
        "\n",
        "#create list of all possible arms ( with specific price configuration)\n",
        "for price_config in tmp:\n",
        "  arm = Arm(price_config)\n",
        "  arms_list.append(arm)\n"
      ],
      "metadata": {
        "id": "hEVi1pRayiLk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_matrix = np.array([[0,0.5,0,0.5,0],\n",
        "                     [0.5,0,0.5,0,0],\n",
        "                     [0,0.5,0,0,0.5],\n",
        "                     [0.5,0,0,0,0.5],\n",
        "                     [0,0.5,0,0.5,0]], dtype = float)\n",
        "num_products_bought = [1, 1, 1, 1, 1]\n",
        "userClass1 = UserClass(100, np.random.dirichlet([1, 1, 1, 1, 1]), num_products_bought, p_matrix )\n",
        "userClass2 = UserClass(200, np.random.dirichlet([1, 1, 1, 1, 1]), num_products_bought, p_matrix )\n",
        "userClass3 = UserClass(50, np.random.dirichlet([1, 1, 1, 1, 1]), num_products_bought, p_matrix )\n",
        "userClasses = [userClass1, userClass2, userClass3]\n",
        "\n",
        "price_vector = [10, 20, 30, 40]\n",
        "p1 = Product(\"p1\", price_vector )\n",
        "p2 = Product(\"p2\", price_vector )\n",
        "p3 = Product(\"p3\", price_vector )\n",
        "p4 = Product(\"p4\", price_vector )\n",
        "p5 = Product(\"p5\", price_vector )\n",
        "\n",
        "T = 300\n",
        "\n",
        "n_experiments = 1000\n",
        "n_step_max = 5\n",
        "lamb= 0.5\n",
        "n_arms = 625\n",
        "\n",
        "buy_probability_matrix =np.random.uniform(0.0,1.0,(5,4)) \n",
        "\n",
        "\n",
        "for e in range(n_experiments):\n",
        "  ts_learner = TS_Learner(n_arms= n_arms)\n",
        "  for t in range(0,T):\n",
        "    #Thompson Sampeling Learner\n",
        "    pulled_arm = ts_learner.pull_arm()\n",
        "    reward = simulate_episode2(p_matrix, n_step_max, initial_product, lamb, buy_probability_matrix, arms_list[pulled_arm].price_vector)               #call the simulate_episode that returns the reward\n",
        "    ts_learner.update(pulled_arm, reward)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "QTTpHtvOm05f",
        "outputId": "33fd6311-4c68-4193-d96b-101f2687ddf5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a04f7dc77b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_experiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mts_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTS_Learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_arms\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mn_arms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    }
  ]
}